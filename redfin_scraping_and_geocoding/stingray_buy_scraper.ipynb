{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_zips(state, city=None, zip_code=None):\n",
    "    zips = pd.read_csv(r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Areas\\zipcode_source\\zip_code_database.csv\")\n",
    "    \n",
    "    if city is None and zip_code is None:\n",
    "        target_zips = zips[zips[\"state\"] == state][\"zip\"].tolist()\n",
    "    elif zip_code is None:\n",
    "        target_zips = zips[(zips[\"primary_city\"] == city) & (zips[\"state\"] == state)][\"zip\"].tolist()\n",
    "    else:\n",
    "        target_zips = [zip_code]\n",
    "    \n",
    "    return target_zips\n",
    "\n",
    "\n",
    "def get_stingray_rgn_id(zip):\n",
    "    query_location_api = f\"https://www.redfin.com/stingray/do/query-location?location={zip}&v=2\"\n",
    "    response = requests.get(query_location_api, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}) \n",
    "    soup = BeautifulSoup(response.text, 'html.parser').text\n",
    "    prefix_removed = soup.split('&&', 1)[1]\n",
    "    data = json.loads(prefix_removed)\n",
    "    try:\n",
    "        region_id = data[\"payload\"][\"exactMatch\"].get(\"id\").split(\"_\",1)[1]\n",
    "        return region_id\n",
    "    except:\n",
    "        print(f\"No Exact match found for zip: {zip}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def build_stingray_gis_params(params):\n",
    "        return \"&\".join(f\"{key}={value}\" for key, value in params.items() if params.get(key) != None)\n",
    "\n",
    "\n",
    "def call_stingray_buy_gis(params_url):\n",
    "    api_url = \"https://www.redfin.com/stingray/api/gis\"\n",
    "    url = f\"{api_url}?{params_url}\"\n",
    "    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'})\n",
    "    soup = BeautifulSoup(response.text, 'html.parser').text\n",
    "    prefix_removed = soup.split('&&', 1)[1]\n",
    "    # print(url)\n",
    "    data = json.loads(prefix_removed)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def parse_stingray_buy_gis(data):\n",
    "    homes = data.get('payload', {}).get('homes', [])\n",
    "    parsed_homes = []\n",
    "    \n",
    "    for home in homes:\n",
    "        lat_long = home.get('latLong', {}).get('value', {})\n",
    "        home_info = {\n",
    "            \"MLS ID\": home.get('mlsId', {}).get('value'),\n",
    "            \"Status\": home.get('mlsStatus'),\n",
    "            \"Price\": home.get('price', {}).get('value'),\n",
    "            \"HOA Fee\": home.get('hoa', {}).get('value'),\n",
    "            \"Square Feet\": home.get('sqFt', {}).get('value'),\n",
    "            \"Price per Square Foot\": home.get('pricePerSqFt', {}).get('value'),\n",
    "            \"Lot Size\": home.get('lotSize', {}).get('value'),\n",
    "            \"Bedrooms\": home.get('beds'),\n",
    "            \"Bathrooms\": home.get('baths'),\n",
    "            \"Location\": home.get('location', {}).get('value'),\n",
    "            \"Stories\": home.get('stories'),\n",
    "            \"Address\": home.get('streetLine', {}).get('value'),\n",
    "            \"City\": home.get('city'),\n",
    "            \"State\": home.get('state'),\n",
    "            \"ZIP Code\": home.get('postalCode', {}).get('value'),\n",
    "            \"Year Built\": home.get('yearBuilt', {}).get('value'),\n",
    "            \"URL\": home.get('url'),\n",
    "            \"Latitude\": lat_long.get('latitude'),\n",
    "            \"Longitude\": lat_long.get('longitude')\n",
    "        }\n",
    "        parsed_homes.append(home_info)\n",
    "    \n",
    "    return parsed_homes\n",
    "\n",
    "\n",
    "def geocode_dataframe(df, latitude_col='Latitude', longitude_col='Longitude'):\n",
    "    import geopandas as gpd\n",
    "    import pandas as pd\n",
    "    \"\"\"\n",
    "    Geocode the given DataFrame based on geographic data files.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data to be geocoded.\n",
    "    longitude_col (str): Name of the column containing longitude values.\n",
    "    latitude_col (str): Name of the column containing latitude values.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Geocoded DataFrame.\n",
    "    \"\"\"\n",
    "    # Convert the DataFrame to a GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df, geometry=gpd.points_from_xy(df[longitude_col], df[latitude_col]), crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    # Load and preprocess demographic areas\n",
    "    demographic_areas = gpd.read_file(r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Areas\\census_block_group_source_nationwide\\v107\\blkgrp.gdb\")\n",
    "    demographic_areas.to_crs(\"EPSG:4326\", inplace=True)\n",
    "    demographic_areas[\"GEOID\"] = (\n",
    "        demographic_areas[\"STATE_FIPS\"].astype(str).str.zfill(2)\n",
    "        + demographic_areas[\"COUNTY_FIPS\"].astype(str).str.zfill(3)\n",
    "        + demographic_areas[\"TRACT_FIPS\"].astype(str).str.zfill(6)\n",
    "        + demographic_areas[\"BLOCKGROUP_FIPS\"].astype(str)\n",
    "    )\n",
    "    demographic_areas = demographic_areas[[\"GEOID\", \"geometry\"]].rename(columns={\"GEOID\": \"cbg_geoid\"})\n",
    "\n",
    "    # Load and preprocess CBSA areas\n",
    "    cbsa_source = gpd.read_file(r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Areas\\cbsa_source\\tl_2020_us_cbsa.shp\")\n",
    "    cbsa_source.to_crs(\"EPSG:4326\", inplace=True)\n",
    "    cbsa_source = cbsa_source[[\"GEOID\", \"NAME\", \"geometry\"]].rename(columns={\"GEOID\": \"cbsa_geoid\", \"NAME\": \"cbsa_name\"})\n",
    "\n",
    "    # Load and preprocess state areas\n",
    "    state_source = gpd.read_file(r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Areas\\state_source\\States_shapefile.shp\")\n",
    "    state_source.to_crs(\"EPSG:4326\", inplace=True)\n",
    "    state_source = state_source[[\"FID\", \"State_Code\", \"geometry\"]].rename(columns={\"FID\": \"state_id\", \"State_Name\": \"state_name\"})\n",
    "\n",
    "    # Perform spatial joins\n",
    "    geocoded_dots = gdf.sjoin(demographic_areas, how=\"left\").drop([\"index_right\"], axis=1)\n",
    "    geocoded_dots = geocoded_dots.sjoin(cbsa_source, how='left').drop([\"index_right\"], axis=1)\n",
    "    geocoded_dots = geocoded_dots.sjoin(state_source, how='left').drop([\"index_right\"], axis=1)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    geocoded_dots = geocoded_dots.drop(['geometry'], axis=1)\n",
    "\n",
    "    return pd.DataFrame(geocoded_dots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Spatial Datasets\n",
    "demographic_areas = gpd.read_file(r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Areas\\census_block_group_source_nationwide\\v107\\blkgrp.gdb\")\n",
    "demographic_areas.to_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "demographic_areas[\"GEOID\"] = \\\n",
    "    demographic_areas[\"STATE_FIPS\"].astype(str).str.zfill(2)  \\\n",
    "    + demographic_areas[\"COUNTY_FIPS\"].astype(str).str.zfill(3) \\\n",
    "    + demographic_areas[\"TRACT_FIPS\"].astype(str).str.zfill(6) \\\n",
    "    + demographic_areas[\"BLOCKGROUP_FIPS\"].astype(str)\n",
    "\n",
    "demographic_areas = demographic_areas[[\"GEOID\", \"geometry\"]].rename(columns={\"GEOID\":\"cbg_geoid\"})\n",
    "\n",
    "cbsa_source = gpd.read_file(r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Areas\\cbsa_source\\tl_2020_us_cbsa.shp\")\n",
    "cbsa_source.to_crs(\"EPSG:4326\", inplace=True)\n",
    "cbsa_source = cbsa_source[[\"GEOID\", \"NAME\", \"geometry\"]].rename(columns={\"GEOID\":\"cbsa_geoid\", \"NAME\": \"cbsa_name\"})\n",
    "\n",
    "state_source = gpd.read_file(r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Areas\\state_source\\States_shapefile.shp\")\n",
    "state_source.to_crs(\"EPSG:4326\", inplace=True)\n",
    "state_source = state_source[[\"FID\", \"State_Code\", \"geometry\"]].rename(columns={\"FID\":\"state_id\", \"State_Name\": \"state_name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Zipcodes to be Scrubbed: 325\n",
      "[83201, 83202, 83203, 83204, 83205, 83206, 83209, 83210, 83211, 83212, 83213, 83214, 83215, 83217, 83218, 83220, 83221, 83223, 83226, 83227, 83228, 83229, 83230, 83232, 83233, 83234, 83235, 83236, 83237, 83238, 83239, 83241, 83243, 83244, 83245, 83246, 83250, 83251, 83252, 83253, 83254, 83255, 83256, 83261, 83262, 83263, 83271, 83272, 83274, 83276, 83277, 83278, 83281, 83283, 83285, 83286, 83287, 83301, 83302, 83303, 83311, 83312, 83313, 83314, 83316, 83318, 83320, 83321, 83322, 83323, 83324, 83325, 83327, 83328, 83330, 83332, 83333, 83334, 83335, 83336, 83337, 83338, 83340, 83341, 83342, 83343, 83344, 83346, 83347, 83348, 83349, 83350, 83352, 83353, 83354, 83355, 83401, 83402, 83403, 83404, 83405, 83406, 83415, 83420, 83421, 83422, 83423, 83424, 83425, 83427, 83428, 83429, 83431, 83433, 83434, 83435, 83436, 83438, 83440, 83441, 83442, 83443, 83444, 83445, 83446, 83448, 83449, 83450, 83451, 83452, 83454, 83455, 83460, 83462, 83463, 83464, 83465, 83466, 83467, 83468, 83469, 83501, 83520, 83522, 83523, 83524, 83525, 83526, 83530, 83531, 83533, 83535, 83536, 83537, 83539, 83540, 83541, 83542, 83543, 83544, 83545, 83546, 83547, 83548, 83549, 83552, 83553, 83554, 83555, 83601, 83602, 83604, 83605, 83606, 83607, 83610, 83611, 83612, 83615, 83616, 83617, 83619, 83622, 83623, 83624, 83626, 83627, 83628, 83629, 83630, 83631, 83632, 83633, 83634, 83635, 83636, 83637, 83638, 83639, 83641, 83642, 83643, 83644, 83645, 83646, 83647, 83648, 83650, 83651, 83652, 83653, 83654, 83655, 83656, 83657, 83660, 83661, 83666, 83669, 83670, 83671, 83672, 83676, 83677, 83680, 83686, 83687, 83701, 83702, 83703, 83704, 83705, 83706, 83707, 83708, 83709, 83711, 83712, 83713, 83714, 83715, 83716, 83717, 83719, 83720, 83721, 83722, 83724, 83725, 83726, 83727, 83728, 83729, 83730, 83731, 83732, 83733, 83735, 83756, 83757, 83799, 83801, 83802, 83803, 83804, 83805, 83806, 83808, 83809, 83810, 83811, 83812, 83813, 83814, 83815, 83816, 83821, 83822, 83823, 83824, 83825, 83826, 83827, 83830, 83832, 83833, 83834, 83835, 83836, 83837, 83839, 83840, 83841, 83842, 83843, 83844, 83845, 83846, 83847, 83848, 83849, 83850, 83851, 83852, 83853, 83854, 83855, 83856, 83857, 83858, 83860, 83861, 83864, 83865, 83866, 83867, 83868, 83869, 83870, 83871, 83872, 83873, 83874, 83876, 83877]\n",
      "0 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83203\n",
      "No Exact match found for zip: 83205\n",
      "No Exact match found for zip: 83206\n",
      "10 Zip Codes Evaluated\n",
      "20 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83230\n",
      "No Exact match found for zip: 83233\n",
      "30 Zip Codes Evaluated\n",
      "40 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83256\n",
      "50 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83303\n",
      "60 Zip Codes Evaluated\n",
      "70 Zip Codes Evaluated\n",
      "80 Zip Codes Evaluated\n",
      "90 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83403\n",
      "100 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83405\n",
      "No Exact match found for zip: 83415\n",
      "110 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83441\n",
      "120 Zip Codes Evaluated\n",
      "130 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83454\n",
      "140 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83531\n",
      "150 Zip Codes Evaluated\n",
      "160 Zip Codes Evaluated\n",
      "170 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83606\n",
      "180 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83630\n",
      "190 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83635\n",
      "200 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83652\n",
      "210 Zip Codes Evaluated\n",
      "220 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83701\n",
      "230 Zip Codes Evaluated\n",
      "240 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83715\n",
      "No Exact match found for zip: 83717\n",
      "No Exact match found for zip: 83721\n",
      "No Exact match found for zip: 83722\n",
      "No Exact match found for zip: 83726\n",
      "250 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83727\n",
      "No Exact match found for zip: 83728\n",
      "No Exact match found for zip: 83729\n",
      "No Exact match found for zip: 83730\n",
      "No Exact match found for zip: 83731\n",
      "No Exact match found for zip: 83733\n",
      "No Exact match found for zip: 83735\n",
      "No Exact match found for zip: 83756\n",
      "No Exact match found for zip: 83757\n",
      "260 Zip Codes Evaluated\n",
      "No Exact match found for zip: 83799\n",
      "270 Zip Codes Evaluated\n",
      "280 Zip Codes Evaluated\n",
      "290 Zip Codes Evaluated\n",
      "300 Zip Codes Evaluated\n",
      "310 Zip Codes Evaluated\n",
      "320 Zip Codes Evaluated\n"
     ]
    }
   ],
   "source": [
    "# GIS Search API\n",
    "\n",
    "import requests\n",
    "\n",
    "Zip = None\n",
    "City = None\n",
    "States = [\"ID\"]\n",
    "\n",
    "\n",
    "target_zips = []\n",
    "\n",
    "for State in States:\n",
    "    target_zips.extend(get_target_zips(State, City, Zip))\n",
    "\n",
    "print(f\"Number of Zipcodes to be Scrubbed: {len(target_zips)}\")\n",
    "\n",
    "print(target_zips)\n",
    "data = []\n",
    "\n",
    "for index, zip in enumerate(target_zips):\n",
    "    if index % 10 == 0:\n",
    "        print(f\"{index} Zip Codes Evaluated\")\n",
    "\n",
    "\n",
    "    params = {\n",
    "    #??Active Listings\n",
    "    \"al\": 1,\n",
    "    #Include Nearby Homes\n",
    "    \"include_nearby_homes\": \"false\",\n",
    "    # Market. ie Seattle\n",
    "    \"market\": None,\n",
    "    # Number of homes to retrieve\n",
    "    \"num_homes\": 350,\n",
    "    #How to Sort the homes\n",
    "    \"ord\": \"days-on-redfin-asc\",\n",
    "    \"page_number\": 1,\n",
    "    \"poly\": None,\n",
    "    #Listing Types\n",
    "    \"sf\": \"1,2,3,4,5,6,7\",\n",
    "    \"start\": None,\n",
    "    \"status\": 9,\n",
    "    # User input property types (currently only single family, townhomes, multifamily : 134)\n",
    "    \"uipt\": \"1,3,4\",\n",
    "    # ??API Version?\n",
    "    \"v\": 8,\n",
    "    \"zoomLevel\": None,\n",
    "    #Type of Region analyzed\n",
    "    \"region_type\" : 2,\n",
    "    \"region_id\" : get_stingray_rgn_id(zip)\n",
    "    }\n",
    "\n",
    "    if params.get(\"region_id\") == None:\n",
    "        continue\n",
    "    else:\n",
    "        url_param = build_stingray_gis_params(params)\n",
    "        json_data = call_stingray_buy_gis(url_param)\n",
    "        list_data = parse_stingray_buy_gis(json_data)\n",
    "        \n",
    "        data.extend(list_data)\n",
    "\n",
    "df= pd.DataFrame(data)\n",
    "\n",
    "df.drop_duplicates(subset=[\"MLS ID\"], inplace=True)\n",
    "\n",
    "df[\"updated_date\"] = datetime.now().date()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Geocoding\n"
     ]
    }
   ],
   "source": [
    "print('Beginning Geocoding')\n",
    "\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df[\"Longitude\"], df[\"Latitude\"]), crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Perform spatial joins\n",
    "geocoded_dots = gdf.sjoin(demographic_areas, how=\"left\").drop([\"index_right\"], axis=1)\n",
    "geocoded_dots = geocoded_dots.sjoin(cbsa_source, how='left').drop([\"index_right\"], axis=1)\n",
    "geocoded_dots = geocoded_dots.sjoin(state_source, how='left').drop([\"index_right\"], axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "geocoded_dots = geocoded_dots.drop(['geometry'], axis=1)\n",
    "\n",
    "homes_geocoded = pd.DataFrame(geocoded_dots)\n",
    "\n",
    "# display(new_rentals_geocoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Deduping\n",
      "9050  Homes Downloaded\n",
      "360  Duplicate Homes\n",
      "25474  Total Homes in Dataset\n"
     ]
    }
   ],
   "source": [
    "print('Beginning Deduping')\n",
    "\n",
    "existing_homes = pd.read_csv(r\"C:\\Users\\mattl\\OneDrive\\Documents\\reibrowser\\Database\\Redfin Data\\for_sale_homes.csv\")\n",
    "\n",
    "\n",
    "\n",
    "existing_homes['MLS ID'] = existing_homes['MLS ID'].astype(str).str.strip()\n",
    "homes_geocoded['MLS ID'] = homes_geocoded['MLS ID'].astype(str).str.strip()\n",
    "\n",
    "# Identify common Property IDs\n",
    "common_property_ids = existing_homes[existing_homes['MLS ID'].isin(homes_geocoded['MLS ID'])]\n",
    "\n",
    "# Filter out these common Property IDs from the existing rentals DataFrame\n",
    "existing_rentals = existing_homes[~existing_homes['MLS ID'].isin(common_property_ids['MLS ID'])]\n",
    "\n",
    "updated_rentals = pd.concat([existing_rentals, homes_geocoded], ignore_index=True)\n",
    "\n",
    "print(homes_geocoded.shape[0], \" Homes Downloaded\")\n",
    "print(common_property_ids.shape[0], \" Duplicate Homes\")\n",
    "print(updated_rentals.shape[0], \" Total Homes in Dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
